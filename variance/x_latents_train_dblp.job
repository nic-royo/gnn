#!/bin/bash

#SBATCH --job-name=x_latents_plot    # Job name
#SBATCH --output=outputs/x_latents_plot_dblp.%j.out # Name of output file (%j expands to jobId)
#SBATCH --cpus-per-task=2                 # Number of CPU cores per task
#SBATCH --gres=gpu:1         # Request 1 GPU or a specific ie. a100_40gb:4, use freeResources to see which are open, then choose node after : 
#SBATCH --time=24:00:00                   # Run time (hh:mm:ss) - run for 48 hours max
#SBATCH --partition=brown                 # Partition name
#SBATCH --mail-type=FAIL,END              # Mail events (NONE, BEGIN, END, FAIL, ALL)
#SBATCH --mem=40G

module load singularity

for num_hops in 2 4
do
    for model_type in rgcn pnrgcn
    do
        for embedding_option in normalize no_normalize
        do
            singularity exec --nv /opt/itu/containers/pytorch/latest python3 variance/x_latents_train_works.py \
            --dataset dblp \
            --data_root /tmp/ \
            --hidden_dim 64 \
            --dropout 0.4262191403432773 \
            --num_hops $num_hops \
            --epochs 500 \
            --learning_rate 0.01 \
            --weight_decay 0.00005 \
            --embedding_option $embedding_option \
            --model_type $model_type 
        done
    done
done
#sbatch variance/x_latents_train_dblp.job