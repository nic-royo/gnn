#!/bin/bash

#SBATCH --job-name=energies    # Job name
#SBATCH --output=../outputs/energies_job.%j.out # Name of output file (%j expands to jobId)
#SBATCH --cpus-per-task=8              # Number of CPU cores per task
#SBATCH --gres=gpu:rtx6000:1              # Request 1 GPU or a specific ie. a100_40gb:4, use freeResources to see which are open, then choose node after :
#SBATCH --time=24:00:00                   # Run time (hh:mm:ss) - run for 48 hours max
#SBATCH --partition=brown,red
#SBATCH --reservation=desktop27              # Partition name
#SBATCH --mail-type=FAIL,END              # Mail events (NONE, BEGIN, END, FAIL, ALL)
#SBATCH --mem=60G

module load singularity
names=('rgcn' 'pnrgcn' 'resrgcn' 'ggrgcn')
datasets=('dblp' 'imdb')
for dataset in "${datasets[@]}"; do
    for name in "${names[@]}"; do
        singularity exec --nv /opt/itu/containers/pytorch/latest python3 run_energies_two_hop.py \
            --dataset $dataset \
            --data_root /tmp/ \
            --hidden_dim 128 \
            --num_hops 128 \
            --model_type $name

    done
done